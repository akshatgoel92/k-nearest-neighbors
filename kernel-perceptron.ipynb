{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist, pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, name):\n",
    "    '''\n",
    "    --------------------\n",
    "    Prepare data\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    data = np.loadtxt(os.path.join(path, name))\n",
    "    X, Y = data[:, 1:], data[:, 0]\n",
    "\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X, Y):\n",
    "    '''\n",
    "    --------------------\n",
    "    Prepare data\n",
    "    --------------------\n",
    "    Parameters:\n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output:\n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    # Data is currently unshuffled; we should shuffle\n",
    "    # each X[i] with its corresponding y[i]\n",
    "    perm = np.random.permutation(max(Y.shape))\n",
    "    X = X[perm, :]\n",
    "    Y = Y[perm]\n",
    "\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, Y, train_percent):\n",
    "    '''\n",
    "    --------------------\n",
    "    Prepare data\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    # Calculate no. of training examples based on user specified percentage\n",
    "    # Here we use 2/3, 1/3 by default as required by the assignment\n",
    "    n_train = round(train_percent*max(Y.shape))\n",
    "    \n",
    "    # Filter the dataframe to get training and testing rows\n",
    "    X_train = X[:n_train, :]\n",
    "    Y_train = Y[:n_train]\n",
    "    \n",
    "    # Validation set\n",
    "    X_val = X[n_train:, :]\n",
    "    Y_val = Y[n_train:]\n",
    "    \n",
    "    # Return statement\n",
    "    return(X_train, X_val, Y_train, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polynomial_kernel(X, X_, d):\n",
    "    '''\n",
    "    --------------------\n",
    "    Prepare data\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    return(np.power(np.dot(X, X.T), d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaussian_kernel(X, X_, c):\n",
    "    '''\n",
    "    --------------------\n",
    "    Prepare data\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    # Compute pairwise distances\n",
    "    K = np.einsum('ij,ij->i',X, X)[:,None] + np.einsum('ij,ij->i',X_,X_) - 2*np.dot(X,X_.T)\n",
    "    \n",
    "    # Then apply parameter c\n",
    "    K = np.exp(K*c)\n",
    "    \n",
    "    # Return statement\n",
    "    return(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(target, pred):\n",
    "    '''\n",
    "    --------------------\n",
    "    Prepare data\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    return np.sum(target==pred)/max(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(history):\n",
    "    '''\n",
    "    --------------------\n",
    "    Get results\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    # Store results\n",
    "    best_epoch = np.array(history[\"dev_accuracies\"]).argmax()\n",
    "    best_training_accuracy = history['accuracies'][best_epoch]\n",
    "    best_dev_accuracy = history['dev_accuracies'][best_epoch]\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"best training accuracy: {history['accuracies'][best_epoch]}\")\n",
    "    print(f\"best dev accuracy: {history['dev_accuracies'][best_epoch]}\")\n",
    "    print(f\"best epoch: {best_epoch}\")\n",
    "    \n",
    "    return(best_epoch, best_training_accuracy, best_dev_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kernel_perceptron(X_train, Y_train, X_dev, Y_dev, epochs, lr, kernel, kernel_args, n_classes):\n",
    "    '''\n",
    "    --------------------\n",
    "    Kernel perceptron algorithm\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    X: Numpy array of training features (shape = 784 X n)\n",
    "    y: Binary (1/-1) training label (shape = n X 1)\n",
    "    --------------------\n",
    "    Output: \n",
    "    w: trained weights\n",
    "    b: trained biases\n",
    "    y_preds: predictions \n",
    "    --------------------\n",
    "    '''\n",
    "    # Store a record of training and validation accuracies at each epoch\n",
    "    history = {\n",
    "        \"train_accuracies\": [],\n",
    "        \"val_accuracies\": []\n",
    "    }\n",
    "    \n",
    "    # Transform X according to the user specified kernel\n",
    "    if kernel == 'polynomial':\n",
    "        X_train = get_polynomial_kernel(X_train, X_train, **kernel_args)\n",
    "    elif kernel == 'gaussian':\n",
    "        X_train = get_gaussian_kernel(X_train, X_train, **kernel_args)\n",
    "    \n",
    "    # Initialize alpha weights\n",
    "    A = np.zeros((n_classes, X_train.shape[0]))\n",
    "    \n",
    "    # Initialize the best accuracy to 0 and update this during training\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    # Store the number of samples for accuracy calculations\n",
    "    n_samples = max(Y_train.shape)\n",
    "    \n",
    "    # Run for a fixed number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Print shapes as a test\n",
    "        print('This is epoch number: {}'.format(epoch))\n",
    "        \n",
    "        # Track number of mistakes for this epoch here\n",
    "        mistakes = 0\n",
    "\n",
    "        # Do this for each example in the dataset\n",
    "        for i in range(X_train.shape[0]):\n",
    "\n",
    "            # Compute the prediction with the current weights:\n",
    "            # dim(A.T) --> (10, 6199), dim(X_train[i, :]) ---> (6199, 1) ====> dim(y_hat) --> 10 X 1\n",
    "            Y_hat = A @ X_train[i, :]\n",
    "            \n",
    "            # Compute predictions check\n",
    "            Y = np.full(n_classes, -1)\n",
    "            Y[int(Y_train[i]) - 1] = 1\n",
    "            \n",
    "            # Compute sign\n",
    "            signs = np.ones(Y_hat.shape)\n",
    "            signs[Y_hat <= 0] = -1\n",
    "            \n",
    "            # Check if the prediction is correct against the labels\n",
    "            # If it is correct we don't need to make any updates: we just move to the next iteration\n",
    "            # If it is not correct then we update the weights and biases in the direction of the label\n",
    "            A[Y*Y_hat <= 0, i] -= (signs[Y*Y_hat <= 0]) \n",
    "            \n",
    "            # Increment mistakes counter\n",
    "            mistakes += int(np.argmax(Y_hat) + 1 != Y_train[i])\n",
    "        \n",
    "        # Print the number of mistakes at the end of each epoch...\n",
    "        print('The number of mistakes made on epoch {} is {} from {} examples...'.format(epoch, mistakes, n_samples))\n",
    "        \n",
    "    # Return statement\n",
    "    return(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kernel_perceptron_training(epochs, lr, \n",
    "                                   data_path = 'data', \n",
    "                                   name = 'zipcombo.dat', \n",
    "                                   kernel = 'polynomial', \n",
    "                                   d = 5, n_classes=10):\n",
    "    '''\n",
    "    --------------------\n",
    "    Run perceptron algorithm to get a base-line\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    X: Numpy array of training features (shape = 784 X n)\n",
    "    y: Binary (1/0) training label (shape = n X 1)\n",
    "    --------------------\n",
    "    Output: \n",
    "    w: trained weights\n",
    "    y_preds: predictions\n",
    "    --------------------\n",
    "    '''\n",
    "    # Set the random seed for random number generator to ensure reproducibility\n",
    "    np.random.seed(132089)\n",
    "\n",
    "    # Prepare data for the perceptron\n",
    "    X, Y = load_data(data_path, name)\n",
    "    \n",
    "    # Shuffle the dataset before splitting it\n",
    "    X, Y = shuffle_data(X, Y)\n",
    "    \n",
    "    # Split the data into training and validation set \n",
    "    X_train, X_val, Y_train, Y_val = split_data(X, Y, 0.66666)\n",
    "    \n",
    "    # Construct kernel arguments dictionary\n",
    "    if kernel == 'polynomial': kernel_args = {'d': d}\n",
    "\n",
    "    # Call the perceptron training with the given epochs\n",
    "    train_kernel_perceptron(X_train, Y_train, X_val, Y_val, epochs, lr, kernel, kernel_args, n_classes)\n",
    "    \n",
    "    # Get results from history\n",
    "    # best_epoch, best_training_accuracy, best_dev_accuracy = get_results(history)\n",
    "    \n",
    "    # Return statement\n",
    "    # return(best_epoch, best_training_accuracy, best_dev_accuracy, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(epochs = 500, lr = 1):\n",
    "    '''\n",
    "    --------------------\n",
    "    Main training loop\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    # Call training function\n",
    "    run_kernel_perceptron_training(epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is epoch number: 0\n",
      "The number of mistakes made on epoch 0 is 1496 from 6199 examples...\n",
      "This is epoch number: 1\n",
      "The number of mistakes made on epoch 1 is 1110 from 6199 examples...\n",
      "This is epoch number: 2\n",
      "The number of mistakes made on epoch 2 is 1075 from 6199 examples...\n",
      "This is epoch number: 3\n",
      "The number of mistakes made on epoch 3 is 1063 from 6199 examples...\n",
      "This is epoch number: 4\n",
      "The number of mistakes made on epoch 4 is 1057 from 6199 examples...\n",
      "This is epoch number: 5\n",
      "The number of mistakes made on epoch 5 is 1056 from 6199 examples...\n",
      "This is epoch number: 6\n",
      "The number of mistakes made on epoch 6 is 1057 from 6199 examples...\n",
      "This is epoch number: 7\n",
      "The number of mistakes made on epoch 7 is 1056 from 6199 examples...\n",
      "This is epoch number: 8\n",
      "The number of mistakes made on epoch 8 is 1055 from 6199 examples...\n",
      "This is epoch number: 9\n",
      "The number of mistakes made on epoch 9 is 1055 from 6199 examples...\n",
      "This is epoch number: 10\n",
      "The number of mistakes made on epoch 10 is 1055 from 6199 examples...\n",
      "This is epoch number: 11\n",
      "The number of mistakes made on epoch 11 is 1056 from 6199 examples...\n",
      "This is epoch number: 12\n",
      "The number of mistakes made on epoch 12 is 1056 from 6199 examples...\n",
      "This is epoch number: 13\n",
      "The number of mistakes made on epoch 13 is 1056 from 6199 examples...\n",
      "This is epoch number: 14\n",
      "The number of mistakes made on epoch 14 is 1055 from 6199 examples...\n",
      "This is epoch number: 15\n",
      "The number of mistakes made on epoch 15 is 1054 from 6199 examples...\n",
      "This is epoch number: 16\n",
      "The number of mistakes made on epoch 16 is 1054 from 6199 examples...\n",
      "This is epoch number: 17\n",
      "The number of mistakes made on epoch 17 is 1054 from 6199 examples...\n",
      "This is epoch number: 18\n",
      "The number of mistakes made on epoch 18 is 1054 from 6199 examples...\n",
      "This is epoch number: 19\n",
      "The number of mistakes made on epoch 19 is 1055 from 6199 examples...\n",
      "This is epoch number: 20\n",
      "The number of mistakes made on epoch 20 is 1055 from 6199 examples...\n",
      "This is epoch number: 21\n",
      "The number of mistakes made on epoch 21 is 1056 from 6199 examples...\n",
      "This is epoch number: 22\n",
      "The number of mistakes made on epoch 22 is 1055 from 6199 examples...\n",
      "This is epoch number: 23\n",
      "The number of mistakes made on epoch 23 is 1055 from 6199 examples...\n",
      "This is epoch number: 24\n",
      "The number of mistakes made on epoch 24 is 1054 from 6199 examples...\n",
      "This is epoch number: 25\n",
      "The number of mistakes made on epoch 25 is 1056 from 6199 examples...\n",
      "This is epoch number: 26\n",
      "The number of mistakes made on epoch 26 is 1058 from 6199 examples...\n",
      "This is epoch number: 27\n",
      "The number of mistakes made on epoch 27 is 1054 from 6199 examples...\n",
      "This is epoch number: 28\n",
      "The number of mistakes made on epoch 28 is 1054 from 6199 examples...\n",
      "This is epoch number: 29\n",
      "The number of mistakes made on epoch 29 is 1054 from 6199 examples...\n",
      "This is epoch number: 30\n",
      "The number of mistakes made on epoch 30 is 1056 from 6199 examples...\n",
      "This is epoch number: 31\n",
      "The number of mistakes made on epoch 31 is 1054 from 6199 examples...\n",
      "This is epoch number: 32\n",
      "The number of mistakes made on epoch 32 is 1055 from 6199 examples...\n",
      "This is epoch number: 33\n",
      "The number of mistakes made on epoch 33 is 1054 from 6199 examples...\n",
      "This is epoch number: 34\n",
      "The number of mistakes made on epoch 34 is 1055 from 6199 examples...\n",
      "This is epoch number: 35\n",
      "The number of mistakes made on epoch 35 is 1054 from 6199 examples...\n",
      "This is epoch number: 36\n",
      "The number of mistakes made on epoch 36 is 1054 from 6199 examples...\n",
      "This is epoch number: 37\n",
      "The number of mistakes made on epoch 37 is 1053 from 6199 examples...\n",
      "This is epoch number: 38\n",
      "The number of mistakes made on epoch 38 is 1053 from 6199 examples...\n",
      "This is epoch number: 39\n",
      "The number of mistakes made on epoch 39 is 1053 from 6199 examples...\n",
      "This is epoch number: 40\n",
      "The number of mistakes made on epoch 40 is 1053 from 6199 examples...\n",
      "This is epoch number: 41\n",
      "The number of mistakes made on epoch 41 is 1053 from 6199 examples...\n",
      "This is epoch number: 42\n",
      "The number of mistakes made on epoch 42 is 1053 from 6199 examples...\n",
      "This is epoch number: 43\n",
      "The number of mistakes made on epoch 43 is 1053 from 6199 examples...\n",
      "This is epoch number: 44\n",
      "The number of mistakes made on epoch 44 is 1053 from 6199 examples...\n",
      "This is epoch number: 45\n",
      "The number of mistakes made on epoch 45 is 1053 from 6199 examples...\n",
      "This is epoch number: 46\n",
      "The number of mistakes made on epoch 46 is 1053 from 6199 examples...\n",
      "This is epoch number: 47\n",
      "The number of mistakes made on epoch 47 is 1053 from 6199 examples...\n",
      "This is epoch number: 48\n",
      "The number of mistakes made on epoch 48 is 1053 from 6199 examples...\n",
      "This is epoch number: 49\n",
      "The number of mistakes made on epoch 49 is 1053 from 6199 examples...\n",
      "This is epoch number: 50\n",
      "The number of mistakes made on epoch 50 is 1053 from 6199 examples...\n",
      "This is epoch number: 51\n",
      "The number of mistakes made on epoch 51 is 1053 from 6199 examples...\n",
      "This is epoch number: 52\n",
      "The number of mistakes made on epoch 52 is 1053 from 6199 examples...\n",
      "This is epoch number: 53\n",
      "The number of mistakes made on epoch 53 is 1053 from 6199 examples...\n",
      "This is epoch number: 54\n",
      "The number of mistakes made on epoch 54 is 1053 from 6199 examples...\n",
      "This is epoch number: 55\n",
      "The number of mistakes made on epoch 55 is 1053 from 6199 examples...\n",
      "This is epoch number: 56\n",
      "The number of mistakes made on epoch 56 is 1053 from 6199 examples...\n",
      "This is epoch number: 57\n",
      "The number of mistakes made on epoch 57 is 1053 from 6199 examples...\n",
      "This is epoch number: 58\n",
      "The number of mistakes made on epoch 58 is 1053 from 6199 examples...\n",
      "This is epoch number: 59\n",
      "The number of mistakes made on epoch 59 is 1053 from 6199 examples...\n",
      "This is epoch number: 60\n",
      "The number of mistakes made on epoch 60 is 1053 from 6199 examples...\n",
      "This is epoch number: 61\n",
      "The number of mistakes made on epoch 61 is 1053 from 6199 examples...\n",
      "This is epoch number: 62\n",
      "The number of mistakes made on epoch 62 is 1053 from 6199 examples...\n",
      "This is epoch number: 63\n",
      "The number of mistakes made on epoch 63 is 1053 from 6199 examples...\n",
      "This is epoch number: 64\n",
      "The number of mistakes made on epoch 64 is 1053 from 6199 examples...\n",
      "This is epoch number: 65\n",
      "The number of mistakes made on epoch 65 is 1053 from 6199 examples...\n",
      "This is epoch number: 66\n",
      "The number of mistakes made on epoch 66 is 1053 from 6199 examples...\n",
      "This is epoch number: 67\n",
      "The number of mistakes made on epoch 67 is 1053 from 6199 examples...\n",
      "This is epoch number: 68\n",
      "The number of mistakes made on epoch 68 is 1053 from 6199 examples...\n",
      "This is epoch number: 69\n",
      "The number of mistakes made on epoch 69 is 1053 from 6199 examples...\n",
      "This is epoch number: 70\n",
      "The number of mistakes made on epoch 70 is 1053 from 6199 examples...\n",
      "This is epoch number: 71\n",
      "The number of mistakes made on epoch 71 is 1053 from 6199 examples...\n",
      "This is epoch number: 72\n",
      "The number of mistakes made on epoch 72 is 1053 from 6199 examples...\n",
      "This is epoch number: 73\n",
      "The number of mistakes made on epoch 73 is 1053 from 6199 examples...\n",
      "This is epoch number: 74\n",
      "The number of mistakes made on epoch 74 is 1053 from 6199 examples...\n",
      "This is epoch number: 75\n",
      "The number of mistakes made on epoch 75 is 1053 from 6199 examples...\n",
      "This is epoch number: 76\n",
      "The number of mistakes made on epoch 76 is 1053 from 6199 examples...\n",
      "This is epoch number: 77\n",
      "The number of mistakes made on epoch 77 is 1053 from 6199 examples...\n",
      "This is epoch number: 78\n",
      "The number of mistakes made on epoch 78 is 1053 from 6199 examples...\n",
      "This is epoch number: 79\n",
      "The number of mistakes made on epoch 79 is 1053 from 6199 examples...\n",
      "This is epoch number: 80\n",
      "The number of mistakes made on epoch 80 is 1053 from 6199 examples...\n",
      "This is epoch number: 81\n",
      "The number of mistakes made on epoch 81 is 1053 from 6199 examples...\n",
      "This is epoch number: 82\n",
      "The number of mistakes made on epoch 82 is 1053 from 6199 examples...\n",
      "This is epoch number: 83\n",
      "The number of mistakes made on epoch 83 is 1053 from 6199 examples...\n",
      "This is epoch number: 84\n",
      "The number of mistakes made on epoch 84 is 1053 from 6199 examples...\n",
      "This is epoch number: 85\n",
      "The number of mistakes made on epoch 85 is 1053 from 6199 examples...\n",
      "This is epoch number: 86\n",
      "The number of mistakes made on epoch 86 is 1053 from 6199 examples...\n",
      "This is epoch number: 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of mistakes made on epoch 87 is 1053 from 6199 examples...\n",
      "This is epoch number: 88\n",
      "The number of mistakes made on epoch 88 is 1053 from 6199 examples...\n",
      "This is epoch number: 89\n",
      "The number of mistakes made on epoch 89 is 1053 from 6199 examples...\n",
      "This is epoch number: 90\n",
      "The number of mistakes made on epoch 90 is 1053 from 6199 examples...\n",
      "This is epoch number: 91\n",
      "The number of mistakes made on epoch 91 is 1053 from 6199 examples...\n",
      "This is epoch number: 92\n",
      "The number of mistakes made on epoch 92 is 1053 from 6199 examples...\n",
      "This is epoch number: 93\n",
      "The number of mistakes made on epoch 93 is 1053 from 6199 examples...\n",
      "This is epoch number: 94\n",
      "The number of mistakes made on epoch 94 is 1053 from 6199 examples...\n",
      "This is epoch number: 95\n",
      "The number of mistakes made on epoch 95 is 1053 from 6199 examples...\n",
      "This is epoch number: 96\n",
      "The number of mistakes made on epoch 96 is 1053 from 6199 examples...\n",
      "This is epoch number: 97\n",
      "The number of mistakes made on epoch 97 is 1053 from 6199 examples...\n",
      "This is epoch number: 98\n",
      "The number of mistakes made on epoch 98 is 1053 from 6199 examples...\n",
      "This is epoch number: 99\n",
      "The number of mistakes made on epoch 99 is 1053 from 6199 examples...\n",
      "This is epoch number: 100\n",
      "The number of mistakes made on epoch 100 is 1053 from 6199 examples...\n",
      "This is epoch number: 101\n",
      "The number of mistakes made on epoch 101 is 1053 from 6199 examples...\n",
      "This is epoch number: 102\n",
      "The number of mistakes made on epoch 102 is 1053 from 6199 examples...\n",
      "This is epoch number: 103\n",
      "The number of mistakes made on epoch 103 is 1053 from 6199 examples...\n",
      "This is epoch number: 104\n",
      "The number of mistakes made on epoch 104 is 1053 from 6199 examples...\n",
      "This is epoch number: 105\n",
      "The number of mistakes made on epoch 105 is 1053 from 6199 examples...\n",
      "This is epoch number: 106\n",
      "The number of mistakes made on epoch 106 is 1053 from 6199 examples...\n",
      "This is epoch number: 107\n",
      "The number of mistakes made on epoch 107 is 1053 from 6199 examples...\n",
      "This is epoch number: 108\n",
      "The number of mistakes made on epoch 108 is 1053 from 6199 examples...\n",
      "This is epoch number: 109\n",
      "The number of mistakes made on epoch 109 is 1053 from 6199 examples...\n",
      "This is epoch number: 110\n",
      "The number of mistakes made on epoch 110 is 1053 from 6199 examples...\n",
      "This is epoch number: 111\n",
      "The number of mistakes made on epoch 111 is 1053 from 6199 examples...\n",
      "This is epoch number: 112\n",
      "The number of mistakes made on epoch 112 is 1053 from 6199 examples...\n",
      "This is epoch number: 113\n",
      "The number of mistakes made on epoch 113 is 1053 from 6199 examples...\n",
      "This is epoch number: 114\n",
      "The number of mistakes made on epoch 114 is 1053 from 6199 examples...\n",
      "This is epoch number: 115\n",
      "The number of mistakes made on epoch 115 is 1053 from 6199 examples...\n",
      "This is epoch number: 116\n",
      "The number of mistakes made on epoch 116 is 1053 from 6199 examples...\n",
      "This is epoch number: 117\n",
      "The number of mistakes made on epoch 117 is 1053 from 6199 examples...\n",
      "This is epoch number: 118\n",
      "The number of mistakes made on epoch 118 is 1053 from 6199 examples...\n",
      "This is epoch number: 119\n",
      "The number of mistakes made on epoch 119 is 1053 from 6199 examples...\n",
      "This is epoch number: 120\n",
      "The number of mistakes made on epoch 120 is 1053 from 6199 examples...\n",
      "This is epoch number: 121\n",
      "The number of mistakes made on epoch 121 is 1053 from 6199 examples...\n",
      "This is epoch number: 122\n",
      "The number of mistakes made on epoch 122 is 1053 from 6199 examples...\n",
      "This is epoch number: 123\n",
      "The number of mistakes made on epoch 123 is 1053 from 6199 examples...\n",
      "This is epoch number: 124\n",
      "The number of mistakes made on epoch 124 is 1053 from 6199 examples...\n",
      "This is epoch number: 125\n",
      "The number of mistakes made on epoch 125 is 1053 from 6199 examples...\n",
      "This is epoch number: 126\n",
      "The number of mistakes made on epoch 126 is 1053 from 6199 examples...\n",
      "This is epoch number: 127\n",
      "The number of mistakes made on epoch 127 is 1053 from 6199 examples...\n",
      "This is epoch number: 128\n",
      "The number of mistakes made on epoch 128 is 1053 from 6199 examples...\n",
      "This is epoch number: 129\n",
      "The number of mistakes made on epoch 129 is 1053 from 6199 examples...\n",
      "This is epoch number: 130\n",
      "The number of mistakes made on epoch 130 is 1053 from 6199 examples...\n",
      "This is epoch number: 131\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-4e5dac1aa4c0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(epochs, lr)\u001b[0m\n\u001b[1;32m     15\u001b[0m     '''\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Call training function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mrun_kernel_perceptron_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-fab2f2dccb23>\u001b[0m in \u001b[0;36mrun_kernel_perceptron_training\u001b[0;34m(epochs, lr, data_path, name, kernel, d, n_classes)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Call the perceptron training with the given epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtrain_kernel_perceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Get results from history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0e04927ef69f>\u001b[0m in \u001b[0;36mtrain_kernel_perceptron\u001b[0;34m(X_train, Y_train, X_dev, Y_dev, epochs, lr, kernel, kernel_args, n_classes)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m# If it is correct we don't need to make any updates: we just move to the next iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# If it is not correct then we update the weights and biases in the direction of the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mY_hat\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msigns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mY_hat\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m# Increment mistakes counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots of losses to see whether it is converging\n",
    "# Shapes of all matrices\n",
    "# Take a look at the actual data in each matrix\n",
    "# Take a look at each weight\n",
    "# Take a look at whether kernel arguments are being sent in correctly\n",
    "# Time run\n",
    "# Make notation more explicit about kernel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
