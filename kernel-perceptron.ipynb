{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist, pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, name):\n",
    "    '''\n",
    "    --------------------\n",
    "    Prepare data\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    data = np.loadtxt(os.path.join(path, name))\n",
    "    X, Y = data[:, 1:], data[:, 0]\n",
    "\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X, Y):\n",
    "    '''\n",
    "    --------------------\n",
    "    Prepare data\n",
    "    --------------------\n",
    "    Parameters:\n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output:\n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    # Data is currently unshuffled; we should shuffle\n",
    "    # each X[i] with its corresponding y[i]\n",
    "    perm = np.random.permutation(max(Y.shape))\n",
    "    X = X[perm, :]\n",
    "    Y = Y[perm]\n",
    "\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, Y, train_percent):\n",
    "    '''\n",
    "    --------------------\n",
    "    Prepare data\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    # Calculate no. of training examples based on user specified percentage\n",
    "    # Here we use 2/3, 1/3 by default as required by the assignment\n",
    "    n_train = round(train_percent*max(Y.shape))\n",
    "    \n",
    "    # Filter the dataframe to get training and testing rows\n",
    "    X_train = X[:n_train]\n",
    "    Y_train = Y[:n_train]\n",
    "    \n",
    "    # Validation set\n",
    "    X_val = X[n_train:]\n",
    "    Y_val = Y[n_train:]\n",
    "    \n",
    "    # Return statement\n",
    "    return(X_train, X_val, Y_train, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polynomial_kernel(X, X_, d):\n",
    "    '''\n",
    "    --------------------\n",
    "    Prepare data\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    return(np.power(np.dot(X, X.T), d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaussian_kernel(X, X_, c):\n",
    "    '''\n",
    "    --------------------\n",
    "    Prepare data\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    # Compute pairwise distances\n",
    "    K = np.einsum('ij,ij->i',X, X)[:,None] + np.einsum('ij,ij->i',X_,X_) - 2*np.dot(X,X_.T)\n",
    "    \n",
    "    # Then apply parameter c\n",
    "    K = np.exp(K*c)\n",
    "    \n",
    "    # Return statement\n",
    "    return(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(target, pred):\n",
    "    '''\n",
    "    --------------------\n",
    "    Prepare data\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    return np.sum(target==pred)/max(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(history):\n",
    "    '''\n",
    "    --------------------\n",
    "    Get results\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    # Store results\n",
    "    best_epoch = np.array(history[\"dev_accuracies\"]).argmax()\n",
    "    best_training_accuracy = history['accuracies'][best_epoch]\n",
    "    best_dev_accuracy = history['dev_accuracies'][best_epoch]\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"best training accuracy: {history['accuracies'][best_epoch]}\")\n",
    "    print(f\"best dev accuracy: {history['dev_accuracies'][best_epoch]}\")\n",
    "    print(f\"best epoch: {best_epoch}\")\n",
    "    \n",
    "    return(best_epoch, best_training_accuracy, best_dev_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kernel_perceptron(X_train, Y_train, X_dev, y_dev, epochs, lr, kernel, kernel_args, n_classes):\n",
    "    '''\n",
    "    --------------------\n",
    "    Kernel perceptron algorithm\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    X: Numpy array of training features (shape = 784 X n)\n",
    "    y: Binary (1/-1) training label (shape = n X 1)\n",
    "    --------------------\n",
    "    Output: \n",
    "    w: trained weights\n",
    "    b: trained biases\n",
    "    y_preds: predictions \n",
    "    --------------------\n",
    "    '''\n",
    "    # Store a record of training and validation accuracies at each epoch\n",
    "    history = {\n",
    "        \"train_accuracies\": [],\n",
    "        \"val_accuracies\": []\n",
    "    }\n",
    "    \n",
    "    # Transform X according to the user specified kernel\n",
    "    if kernel == 'polynomial':\n",
    "        X_train = get_polynomial_kernel(X_train, X_train, **kernel_args)\n",
    "    elif kernel == 'gaussian':\n",
    "        X_train = get_gaussian_kernel(X_train, X_train, **kernel_args)\n",
    "    \n",
    "    # Initialize alpha weights\n",
    "    A = np.zeros((n_classes, X_train.shape[0]))\n",
    "    \n",
    "    # Initialize the best accuracy to 0 and update this during training\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    # Run for a fixed number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Shuffle data at start of each epoch\n",
    "        X_train, Y_train = shuffle_data(X_train, Y_train)\n",
    "        \n",
    "        # Do this for each example in the dataset\n",
    "        for i in range(X_train.shape[0]):\n",
    "\n",
    "            # Compute the prediction with the current weights: add 1 to take zero indexing into account\n",
    "            # dim(A.T) --> (10, 6199), dim(X_train[i, :]) ---> (6199, 1) ====> dim(y_hat) --> 10 X 1\n",
    "            y_hat = (A @ X_train[i, :]\n",
    "            \n",
    "            # Check if the prediction is correct against the labels\n",
    "            # If it is correct we don't need to make any updates: we just move to the next iteration\n",
    "            # If it is not correct then we update the weights and biases in the direction of the label\n",
    "            if y_hat != Y_train[i]: A[y_hat - 1, :] += \n",
    "\n",
    "    \n",
    "    # Return statement\n",
    "    return(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kernel_perceptron_training(epochs, lr, data_path = 'data', name = 'zipcombo.dat', \n",
    "                                   kernel = 'polynomial', d = 2, n_classes=10):\n",
    "    '''\n",
    "    --------------------\n",
    "    Run perceptron algorithm to get a base-line\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    X: Numpy array of training features (shape = 784 X n)\n",
    "    y: Binary (1/0) training label (shape = n X 1)\n",
    "    --------------------\n",
    "    Output: \n",
    "    w: trained weights\n",
    "    y_preds: predictions\n",
    "    --------------------\n",
    "    '''\n",
    "    # Set the random seed for random number generator to ensure reproducibility\n",
    "    np.random.seed(132089)\n",
    "\n",
    "    # Prepare data for the perceptron\n",
    "    X, Y = load_data(data_path, name)\n",
    "    \n",
    "    # Shuffle the dataset before splitting it\n",
    "    X, Y = shuffle_data(X, Y)\n",
    "    \n",
    "    # Split the data into training and validation set \n",
    "    X_train, Y_train, X_val, Y_val = split_data(X, Y, 0.66666)\n",
    "    \n",
    "    # Construct kernel arguments dictionary\n",
    "    if kernel == 'polynomial': kernel_args = {'d': d}\n",
    "\n",
    "    # Call the perceptron training with the given epochs\n",
    "    history = train_kernel_perceptron(X_train, Y_train, X_val, Y_val, epochs, lr, kernel, kernel_args, n_classes)\n",
    "    \n",
    "    # Get results from history\n",
    "    best_epoch, best_training_accuracy, best_dev_accuracy = get_results(history)\n",
    "    \n",
    "    # Return statement\n",
    "    return(best_epoch, best_training_accuracy, best_dev_accuracy, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(epochs = 1000, lr = 1):\n",
    "    '''\n",
    "    --------------------\n",
    "    Main training loop\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    weights: Current set of weights\n",
    "    biases: Current set of biases\n",
    "    gradients: Current set of gradients\n",
    "    learning_rate: parameter to guide SGD step size\n",
    "    --------------------\n",
    "    Output: \n",
    "    Updated weights and biases\n",
    "    --------------------\n",
    "    '''\n",
    "    # Call training function\n",
    "    best_epoch, best_accuracy, best_loss, history = run_kernel_perceptron_training(epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6199, 6199)\n",
      "(6199, 10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-9e3e13522846>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(epochs, lr)\u001b[0m\n\u001b[1;32m     15\u001b[0m     '''\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Call training function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mbest_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_kernel_perceptron_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-46786119f3b9>\u001b[0m in \u001b[0;36mrun_kernel_perceptron_training\u001b[0;34m(epochs, lr, data_path, name, kernel, d, n_classes)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Call the perceptron training with the given epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_kernel_perceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Get results from history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-da04de867c44>\u001b[0m in \u001b[0;36mtrain_kernel_perceptron\u001b[0;34m(X_train, Y_train, X_dev, y_dev, epochs, lr, kernel, kernel_args, n_classes)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m# If it is correct we don't need to make any updates: we just move to the next iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# If it is not correct then we update the weights and biases in the direction of the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_hat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_i\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Now we make predictions after epoch updates on entire training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
