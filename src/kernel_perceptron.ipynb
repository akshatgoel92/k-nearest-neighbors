{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(alpha, K_examples):\n",
    "    '''\n",
    "    Returns raw predictions and class predictions\n",
    "    given alpha weights and Gram matrix K_examples.\n",
    "    '''\n",
    "    # Take the maximum argument in each column\n",
    "    Y_hat = alpha @ K_examples\n",
    "    preds = np.argmax(Y_hat, axis = 0)\n",
    "    \n",
    "    # Return statement\n",
    "    return(Y_hat, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_update(Y_train, Y_hat, alpha, n_classes, i):\n",
    "    '''\n",
    "    Returns raw predictions and class predictions\n",
    "    given alpha weights and Gram matrix K_examples.\n",
    "    '''\n",
    "    # Now first make a matrix Y with dim(Y) ---> (n_classes,) which is only filled with -1\n",
    "    # Then get the label from the Y_train matrix\n",
    "    # If this label is 6 then we want to change the 6th index to 1\n",
    "    Y = np.full(n_classes, -1)\n",
    "    Y[int(Y_train[i])] = 1\n",
    "            \n",
    "    # Compute sign of predictions\n",
    "    # This is used in the update\n",
    "    signs = np.ones(Y_hat.shape)\n",
    "    signs[Y_hat <= 0] = -1\n",
    "            \n",
    "    # Check if the prediction is correct against the labels\n",
    "    # If it is correct we don't need to make any updates: we just move to the next iteration\n",
    "    # If it is not correct then we update the weights and biases in the direction of the label\n",
    "    alpha[Y*Y_hat <= 0, i] -= (signs[Y*Y_hat <= 0])\n",
    "    \n",
    "    return(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kernel_perceptron(X_train, Y_train, X_val, Y_val, epochs, kernel_type, d, n_classes):\n",
    "    '''\n",
    "    This is the main training loop for\n",
    "    the kernel perceptron algorithm.\n",
    "    '''\n",
    "    # Store a record of training and validation accuracies and other data from each epoch\n",
    "    history = {\n",
    "        \"train_accuracies\": [],\n",
    "        \"val_accuracies\": [],\n",
    "        \"train_cf\": [],\n",
    "        \"val_cf\": []\n",
    "    }\n",
    "    \n",
    "    # Transform X according to the user specified kernel\n",
    "    # Can be either polynomial kernel or Gaussian kernel\n",
    "    # Do this for both training and validation set\n",
    "    if kernel_type == 'polynomial':\n",
    "        K_train = helpers.get_polynomial_kernel(X_train, X_train, d)\n",
    "        K_val = helpers.get_polynomial_kernel(X_train, X_val, d)\n",
    "    \n",
    "    elif kernel_type == 'gaussian':\n",
    "        K_train = helpers.get_gaussian_kernel(X_train, X_train, d)\n",
    "        K_val = helpers.get_gaussian_kernel(X_train, X_val, d)\n",
    "    \n",
    "    # Initialize alpha weights and store \n",
    "    # the number of samples\n",
    "    alpha = np.zeros((n_classes, K_train.shape[0]))\n",
    "    n_samples = max(Y_train.shape)\n",
    "    \n",
    "    # Run for a fixed user-specified number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Print the epoch number to track progress\n",
    "        print('This is epoch number: {}'.format(epoch))\n",
    "\n",
    "        # Do this for each example in the dataset\n",
    "        for i in range(n_samples):\n",
    "            # Compute the prediction with the current weights:\n",
    "            # dim(A) --> (10, 6199), dim(X_train[i, :]) ---> (6199, 1) ====> dim(y_hat) --> 10 X 1\n",
    "            Y_hat, _ = get_predictions(alpha, K_train[i, :])\n",
    "            \n",
    "            # Perform update by calling the function above\n",
    "            alpha = get_update(Y_train, Y_hat, alpha, n_classes, i)\n",
    "            \n",
    "        # We finally compute predictions and accuracy at the end of each epoch\n",
    "        # It is a mistake if the class with the highest predicted value does not equal the true label\n",
    "        # mistakes += int((np.argmax(Y_hat) + 1) != int(Y_train[i]))\n",
    "        Y_hat_train, preds_train = get_predictions(alpha, K_train)\n",
    "        train_accuracy = helpers.get_accuracy(Y_train, preds_train)\n",
    "            \n",
    "        # Now we compute validation predictions\n",
    "        Y_hat_val, preds_val = get_predictions(alpha, K_val)\n",
    "        val_accuracy = helpers.get_accuracy(Y_val, preds_val)\n",
    "        \n",
    "        # At the end of each epoch we get confusion matrices\n",
    "        train_cf = helpers.get_confusion_matrix(Y_train, preds_train)\n",
    "        val_cf = helpers.get_confusion_matrix(Y_val, preds_val)\n",
    "        \n",
    "        # We append to the history dictionary as a record\n",
    "        history['train_accuracies'].append(train_accuracy)\n",
    "        history['val_accuracies'].append(val_accuracy)\n",
    "        history['train_cf'].append(train_cf)\n",
    "        history['val_cf'].append(val_cf)\n",
    "        \n",
    "        # We print the accuracies at the end of each epoch\n",
    "        msg = '{} accuracy on epoch {}: {}'\n",
    "        print(msg.format('train', epoch, train_accuracy))\n",
    "        print(msg.format('validation', epoch, val_accuracy))\n",
    "    \n",
    "    # Return statement\n",
    "    return(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_perceptron_training(epochs, data_path = os.path.join('..', 'data'), name = 'zipcombo.dat', \n",
    "                            kernel_type = 'polynomial', d = 5, n_classes=10, train_percent=0.8):\n",
    "    '''\n",
    "    Execute the training steps above and generate\n",
    "    the results that have been specified in the report.\n",
    "    '''\n",
    "    # Prepare data for the perceptron\n",
    "    X, Y = helpers.load_data(data_path, name)\n",
    "    \n",
    "    # Shuffle the dataset before splitting it\n",
    "    X, Y = helpers.shuffle_data(X, Y)\n",
    "    \n",
    "    # Split the data into training and validation set \n",
    "    X_train, X_val, Y_train, Y_val = helpers.split_data(X, Y, train_percent)\n",
    "\n",
    "    # Call the perceptron training with the given epochs\n",
    "    history = train_kernel_perceptron(X_train, Y_train, \n",
    "                                      X_val, Y_val, epochs,\n",
    "                                      kernel_type, d, n_classes)\n",
    "    \n",
    "    # Return best epoch according to dev. accuracy and the associated accuracies on both datasets\n",
    "    best_epoch, best_training_accuracy, best_dev_accuracy = helpers.get_best_results(history)\n",
    "    \n",
    "    # Return statement\n",
    "    return(history, best_epoch, best_training_accuracy, best_dev_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold_cross_val(epochs, data_path = os.path.join('..', 'data'), \n",
    "                         name = 'zipcombo.dat', kernel_type = 'polynomial', \n",
    "                         d = 5, n_classes=10, k = 5):\n",
    "    '''\n",
    "    Execute the training steps above and generate\n",
    "    the results that have been specified in the report.\n",
    "    '''\n",
    "    # Prepare data for the perceptron\n",
    "    X, Y = helpers.load_data(data_path, name)\n",
    "    \n",
    "    # Shuffle the dataset before splitting it\n",
    "    X, Y = helpers.shuffle_data(X, Y)\n",
    "    \n",
    "    # Split the data into training and validation set \n",
    "    X_folds, Y_folds = helpers.get_k_folds(X, Y, k)\n",
    "    \n",
    "    # Initiate histories object\n",
    "    histories = []\n",
    "    \n",
    "    # Now go through each fold : every fold becomes the hold-out set at least once\n",
    "    for fold_no in range(k):\n",
    "        \n",
    "        # Put in the x-values\n",
    "        X_train = np.concatenate(X_folds[:fold_no] + X_folds[fold_no+1:])\n",
    "        X_val = X_folds[fold_no]\n",
    "        \n",
    "        # Put in the Y values\n",
    "        Y_train = np.concatenate(Y_folds[:fold_no] + Y_folds[fold_no+1:])\n",
    "        Y_val =  Y_folds[fold_no]\n",
    "        \n",
    "        # Call the perceptron training with the given epochs\n",
    "        history = train_kernel_perceptron(X_train, Y_train, \n",
    "                                          X_val, Y_val, epochs,\n",
    "                                          kernel_type, d, n_classes)\n",
    "        \n",
    "        # Append to the histories file the epoch by epoch record of each fold\n",
    "        histories.append(history)\n",
    "    \n",
    "    # Get avg. accuracies by epoch across folds\n",
    "    avg_history = helpers.get_avg_results(histories)\n",
    "    \n",
    "    # Return best epoch according to dev. accuracy and the associated accuracies on both datasets\n",
    "    best_epoch, best_training_accuracy, best_dev_accuracy = helpers.get_best_results(avg_history)\n",
    "        \n",
    "    # Return statement\n",
    "    return(avg_history, best_epoch, best_training_accuracy, best_dev_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple(params, kwargs):\n",
    "    \n",
    "    histories = {\n",
    "        \n",
    "        'params': params, \n",
    "        'history': [],\n",
    "        'best_epoch': [],\n",
    "        'best_training_accuracy': [],\n",
    "        'best_dev_accuracy': [],\n",
    "    }\n",
    "    \n",
    "    for param in params:\n",
    "        history, best_epoch, best_training_accuracy, best_dev_accuracy = run_perceptron_training(**kwargs, d=param)\n",
    "        histories['history'].append(history)\n",
    "        histories['best_epoch'].append(best_epoch)\n",
    "        histories['best_training_accuracy'].append(best_training_accuracy)\n",
    "        histories['best_dev_accuracy'].append(best_dev_accuracy)\n",
    "    \n",
    "    return(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(params, kwargs):\n",
    "    \n",
    "    \n",
    "    histories = {\n",
    "        \n",
    "            'params': params, \n",
    "            'best_epoch': [],\n",
    "            'best_training_accuracy': [],\n",
    "            'best_dev_accuracy': [],\n",
    "    }\n",
    "    \n",
    "    for param in params: \n",
    "        _, best_epoch, best_training_accuracy, best_dev_accuracy = run_k_fold_cross_val(d=param, **kwargs)\n",
    "        histories['best_epoch'].append(best_epoch)\n",
    "        histories['best_training_accuracy'].append(best_training_accuracy)\n",
    "        histories['best_dev_accuracy'].append(best_dev_accuracy)\n",
    "    \n",
    "    \n",
    "    return(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(13290138)\n",
    "\n",
    "params = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "\n",
    "multiple_run_args = {\n",
    "    \n",
    "    'epochs': 100, \n",
    "    'data_path': os.path.join('..', 'data'), \n",
    "    'name': 'zipcombo.dat', \n",
    "    'kernel_type': 'polynomial', \n",
    "    'n_classes': 10,\n",
    "    'train_percent': 0.8   \n",
    "}\n",
    "\n",
    "\n",
    "# Call training function once\n",
    "multiple_histories = run_multiple(params, multiple_run_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.8857219682710405\n",
      "validation accuracy on epoch 0: 0.8774193548387097\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9159720354934122\n",
      "validation accuracy on epoch 1: 0.9021505376344086\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.911669803710675\n",
      "validation accuracy on epoch 0: 0.8935483870967742\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9228287173971498\n",
      "validation accuracy on epoch 1: 0.9\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.8822264049475665\n",
      "validation accuracy on epoch 0: 0.8801075268817204\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9200053777897285\n",
      "validation accuracy on epoch 1: 0.9075268817204301\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9184030111574136\n",
      "validation accuracy on epoch 0: 0.898870360408822\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9100685576018283\n",
      "validation accuracy on epoch 1: 0.891877353415815\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.892189810458395\n",
      "validation accuracy on epoch 0: 0.8628294782140936\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9214948245731953\n",
      "validation accuracy on epoch 1: 0.8994082840236687\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9451465447700995\n",
      "validation accuracy on epoch 0: 0.9349462365591398\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9788921753159452\n",
      "validation accuracy on epoch 1: 0.9564516129032258\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9598010217800484\n",
      "validation accuracy on epoch 0: 0.9370967741935484\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9831944070986824\n",
      "validation accuracy on epoch 1: 0.9564516129032258\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9639688088195751\n",
      "validation accuracy on epoch 0: 0.939247311827957\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9799677332616294\n",
      "validation accuracy on epoch 1: 0.946236559139785\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9684097324909262\n",
      "validation accuracy on epoch 0: 0.9419042495965573\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9766097593762603\n",
      "validation accuracy on epoch 1: 0.9462076385153309\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9341309315768248\n",
      "validation accuracy on epoch 0: 0.9101667563206025\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9772818927275171\n",
      "validation accuracy on epoch 1: 0.9445938676707908\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9841355203011563\n",
      "validation accuracy on epoch 0: 0.9564516129032258\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9917988706641571\n",
      "validation accuracy on epoch 1: 0.9634408602150538\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9811777359505244\n",
      "validation accuracy on epoch 0: 0.9526881720430107\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9908577574616833\n",
      "validation accuracy on epoch 1: 0.9639784946236559\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9776821726270503\n",
      "validation accuracy on epoch 0: 0.9559139784946237\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9848077440172089\n",
      "validation accuracy on epoch 1: 0.9586021505376344\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.980104852802796\n",
      "validation accuracy on epoch 0: 0.9515868746637978\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9913966931039118\n",
      "validation accuracy on epoch 1: 0.9644970414201184\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9630326656808711\n",
      "validation accuracy on epoch 0: 0.9419042495965573\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.979029439440785\n",
      "validation accuracy on epoch 1: 0.9585798816568047\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9861521914493143\n",
      "validation accuracy on epoch 0: 0.9634408602150538\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9958322129604732\n",
      "validation accuracy on epoch 1: 0.9709677419354839\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9813121806937348\n",
      "validation accuracy on epoch 0: 0.9553763440860215\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9944877655283678\n",
      "validation accuracy on epoch 1: 0.964516129032258\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9795643990319979\n",
      "validation accuracy on epoch 0: 0.9510752688172043\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9962355471901049\n",
      "validation accuracy on epoch 1: 0.9688172043010753\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9850786396020971\n",
      "validation accuracy on epoch 0: 0.9618074233458849\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9891114397096384\n",
      "validation accuracy on epoch 1: 0.9639591178052717\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9862884796343595\n",
      "validation accuracy on epoch 0: 0.9585798816568047\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9954294932114531\n",
      "validation accuracy on epoch 1: 0.9639591178052717\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9829255176122613\n",
      "validation accuracy on epoch 0: 0.9473118279569892\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9974455498789997\n",
      "validation accuracy on epoch 1: 0.9618279569892473\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9872277493949987\n",
      "validation accuracy on epoch 0: 0.9553763440860215\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9955633234740522\n",
      "validation accuracy on epoch 1: 0.9672043010752688\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.986555525678946\n",
      "validation accuracy on epoch 0: 0.9688172043010753\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9966388814197364\n",
      "validation accuracy on epoch 1: 0.9779569892473118\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9833310928888291\n",
      "validation accuracy on epoch 0: 0.9601936525013448\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9958327732222073\n",
      "validation accuracy on epoch 1: 0.9725658956428187\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9922032531254201\n",
      "validation accuracy on epoch 0: 0.9435180204410973\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9958327732222073\n",
      "validation accuracy on epoch 1: 0.9607315761161915\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9915299811777359\n",
      "validation accuracy on epoch 0: 0.9650537634408602\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9963699919333154\n",
      "validation accuracy on epoch 1: 0.9650537634408602\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9893788652863673\n",
      "validation accuracy on epoch 0: 0.9575268817204301\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9985211078246841\n",
      "validation accuracy on epoch 1: 0.9629032258064516\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9870933046517881\n",
      "validation accuracy on epoch 0: 0.964516129032258\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9973111051357892\n",
      "validation accuracy on epoch 1: 0.967741935483871\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9895147197203925\n",
      "validation accuracy on epoch 0: 0.9628832705755783\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9973114665949725\n",
      "validation accuracy on epoch 1: 0.9709521247982786\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9924721064659229\n",
      "validation accuracy on epoch 0: 0.9661108122646584\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9973114665949725\n",
      "validation accuracy on epoch 1: 0.9677245831091985\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9905888679752621\n",
      "validation accuracy on epoch 0: 0.9602150537634409\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9986555525678946\n",
      "validation accuracy on epoch 1: 0.9682795698924731\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9870933046517881\n",
      "validation accuracy on epoch 0: 0.9559139784946237\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9983866630814735\n",
      "validation accuracy on epoch 1: 0.9666666666666667\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9895133100295779\n",
      "validation accuracy on epoch 0: 0.9629032258064516\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9979833288518419\n",
      "validation accuracy on epoch 1: 0.9763440860215054\n",
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9919343997849174\n",
      "validation accuracy on epoch 0: 0.972027972027972\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9979835999462293\n",
      "validation accuracy on epoch 1: 0.9763313609467456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.991127839763409\n",
      "validation accuracy on epoch 0: 0.9623453469607316\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 0.9977147466057266\n",
      "validation accuracy on epoch 1: 0.9639591178052717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'params': [1, 2, 3, 4, 5, 6, 7],\n",
       " 'best_epoch': [1, 1, 1, 1, 1, 1, 1],\n",
       " 'best_training_accuracy': [0.9180739025710627,\n",
       "  0.979189193556007,\n",
       "  0.9875781009375493,\n",
       "  0.9942192917200074,\n",
       "  0.9962626602434405,\n",
       "  0.9973650276167467,\n",
       "  0.9981447782106331],\n",
       " 'best_dev_accuracy': [0.9001926113588645,\n",
       "  0.9499882582264716,\n",
       "  0.9618196856906535,\n",
       "  0.9664438621758722,\n",
       "  0.9680573438141675,\n",
       "  0.966875126527732,\n",
       "  0.9703161602665323]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set keyword arguments for grid search\n",
    "grid_search_args = {\n",
    "    \n",
    "    'epochs': 100, \n",
    "    'data_path': os.path.join('..', 'data'), \n",
    "    'name': 'zipcombo.dat', \n",
    "    'kernel_type': 'polynomial', \n",
    "    'n_classes': 10,\n",
    "    'k': 5\n",
    "    \n",
    "}\n",
    "\n",
    "cross_val_histories = run_grid_search(params, grid_search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do for this script:\n",
    "# Make plots of losses to see whether it is converging\n",
    "# Check shapes of all matrices\n",
    "# Take a look at the actual data in each matrix\n",
    "# Take a look at each weight\n",
    "# Take a look at whether kernel arguments are being sent in correctly\n",
    "# Test Gaussian kernel\n",
    "# Implement 'many runs' mode to do 20 runs\n",
    "\n",
    "# Potential report content\n",
    "# Talk about effect of dimensionality on overfitting\n",
    "# Expand the Gaussian kernel into its feature map and speak about the role of c as a regularizer\n",
    "# Try to answer the question: for what values of C does Gaussian kernel mimic a polynomial kernel? \n",
    "# Potentially make a plot for the above\n",
    "\n",
    "\n",
    "# Questions: \n",
    "# Do we shuffle the data at each epoch?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
