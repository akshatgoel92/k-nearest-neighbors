{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(alpha, K_examples):\n",
    "    '''\n",
    "    Returns raw predictions and class predictions\n",
    "    given alpha weights and Gram matrix K_examples.\n",
    "    '''\n",
    "    # Take the maximum argument in each column\n",
    "    Y_hat = alpha @ K_examples\n",
    "    preds = np.argmax(Y_hat, axis = 0)\n",
    "    \n",
    "    # Return statement\n",
    "    return(Y_hat, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_update(Y_train, Y_hat, alpha, n_classes, i):\n",
    "    '''\n",
    "    Returns raw predictions and class predictions\n",
    "    given alpha weights and Gram matrix K_examples.\n",
    "    '''\n",
    "    # Now first make a matrix Y with dim(Y) ---> (n_classes,) which is only filled with -1\n",
    "    # Then get the label from the Y_train matrix\n",
    "    # If this label is 6 then we want to change the 6th index to 1\n",
    "    Y = np.full(n_classes, -1)\n",
    "    Y[int(Y_train[i])] = 1\n",
    "            \n",
    "    # Compute sign of predictions\n",
    "    # This is used in the update\n",
    "    signs = np.ones(Y_hat.shape)\n",
    "    signs[Y_hat <= 0] = -1\n",
    "            \n",
    "    # Check if the prediction is correct against the labels\n",
    "    # If it is correct we don't need to make any updates: we just move to the next iteration\n",
    "    # If it is not correct then we update the weights and biases in the direction of the label\n",
    "    alpha[Y*Y_hat <= 0, i] -= (signs[Y*Y_hat <= 0])\n",
    "    \n",
    "    return(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kernel_perceptron(X_train, Y_train, X_val, Y_val, epochs, kernel_type, d, n_classes):\n",
    "    '''\n",
    "    This is the main training loop for\n",
    "    the kernel perceptron algorithm.\n",
    "    '''\n",
    "    # Store a record of training and validation accuracies and other data from each epoch\n",
    "    history = {\n",
    "        \"train_accuracies\": [],\n",
    "        \"val_accuracies\": [],\n",
    "        \"train_cf\": [],\n",
    "        \"val_cf\": []\n",
    "    }\n",
    "    \n",
    "    # Transform X according to the user specified kernel\n",
    "    # Can be either polynomial kernel or Gaussian kernel\n",
    "    # Do this for both training and validation set\n",
    "    if kernel_type == 'polynomial':\n",
    "        K_train = helpers.get_polynomial_kernel(X_train, X_train, d)\n",
    "        K_val = helpers.get_polynomial_kernel(X_train, X_val, d)\n",
    "    \n",
    "    elif kernel_type == 'gaussian':\n",
    "        K_train = helpers.get_gaussian_kernel(X_train, X_train, d)\n",
    "        K_val = helpers.get_gaussian_kernel(X_train, X_val, d)\n",
    "    \n",
    "    # Initialize alpha weights and store \n",
    "    # the number of samples\n",
    "    alpha = np.zeros((n_classes, K_train.shape[0]))\n",
    "    n_samples = max(Y_train.shape)\n",
    "    \n",
    "    # Run for a fixed user-specified number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Print the epoch number to track progress\n",
    "        print('This is epoch number: {}'.format(epoch))\n",
    "\n",
    "        # Do this for each example in the dataset\n",
    "        for i in range(n_samples):\n",
    "            # Compute the prediction with the current weights:\n",
    "            # dim(A) --> (10, 6199), dim(X_train[i, :]) ---> (6199, 1) ====> dim(y_hat) --> 10 X 1\n",
    "            Y_hat, _ = get_predictions(alpha, K_train[i, :])\n",
    "            \n",
    "            # Perform update by calling the function above\n",
    "            alpha = get_update(Y_train, Y_hat, alpha, n_classes, i)\n",
    "            \n",
    "        # We finally compute predictions and accuracy at the end of each epoch\n",
    "        # It is a mistake if the class with the highest predicted value does not equal the true label\n",
    "        # mistakes += int((np.argmax(Y_hat) + 1) != int(Y_train[i]))\n",
    "        Y_hat_train, preds_train = get_predictions(alpha, K_train)\n",
    "        train_accuracy = helpers.get_accuracy(Y_train, preds_train)\n",
    "            \n",
    "        # Now we compute validation predictions\n",
    "        Y_hat_val, preds_val = get_predictions(alpha, K_val)\n",
    "        val_accuracy = helpers.get_accuracy(Y_val, preds_val)\n",
    "        \n",
    "        # At the end of each epoch we get confusion matrices\n",
    "        train_cf = helpers.get_confusion_matrix(Y_train, preds_train)\n",
    "        val_cf = helpers.get_confusion_matrix(Y_val, preds_val)\n",
    "        \n",
    "        # We append to the history dictionary as a record\n",
    "        history['train_accuracies'].append(train_accuracy)\n",
    "        history['val_accuracies'].append(val_accuracy)\n",
    "        history['train_cf'].append(train_cf)\n",
    "        history['val_cf'].append(val_cf)\n",
    "        \n",
    "        # We print the accuracies at the end of each epoch\n",
    "        msg = '{} accuracy on epoch {}: {}'\n",
    "        print(msg.format('train', epoch, train_accuracy))\n",
    "        print(msg.format('validation', epoch, val_accuracy))\n",
    "    \n",
    "    # Return statement\n",
    "    return(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_perceptron_training(epochs, data_path = os.path.join('..', 'data'), name = 'zipcombo.dat', \n",
    "                            kernel_type = 'polynomial', d = 5, n_classes=10, train_percent=0.8):\n",
    "    '''\n",
    "    Execute the training steps above and generate\n",
    "    the results that have been specified in the report.\n",
    "    '''\n",
    "    # Prepare data for the perceptron\n",
    "    X, Y = helpers.load_data(data_path, name)\n",
    "    \n",
    "    # Shuffle the dataset before splitting it\n",
    "    X, Y = helpers.shuffle_data(X, Y)\n",
    "    \n",
    "    # Split the data into training and validation set \n",
    "    X_train, X_val, Y_train, Y_val = helpers.split_data(X, Y, train_percent)\n",
    "\n",
    "    # Call the perceptron training with the given epochs\n",
    "    history = train_kernel_perceptron(X_train, Y_train, \n",
    "                                      X_val, Y_val, epochs,\n",
    "                                      kernel_type, d, n_classes)\n",
    "    \n",
    "    # Return best epoch according to dev. accuracy and the associated accuracies on both datasets\n",
    "    best_epoch, best_training_accuracy, best_dev_accuracy = helpers.get_best_results(history)\n",
    "    \n",
    "    # Return statement\n",
    "    return(history, best_epoch, best_training_accuracy, best_dev_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is epoch number: 0\n",
      "train accuracy on epoch 0: 0.9908814589665653\n",
      "validation accuracy on epoch 0: 0.9649122807017544\n",
      "This is epoch number: 1\n",
      "train accuracy on epoch 1: 1.0\n",
      "validation accuracy on epoch 1: 0.9714912280701754\n",
      "This is epoch number: 2\n",
      "train accuracy on epoch 2: 0.9969604863221885\n",
      "validation accuracy on epoch 2: 0.9736842105263158\n",
      "This is epoch number: 3\n",
      "train accuracy on epoch 3: 1.0\n",
      "validation accuracy on epoch 3: 0.9736842105263158\n",
      "This is epoch number: 4\n",
      "train accuracy on epoch 4: 1.0\n",
      "validation accuracy on epoch 4: 0.9736842105263158\n",
      "This is epoch number: 5\n",
      "train accuracy on epoch 5: 1.0\n",
      "validation accuracy on epoch 5: 0.9736842105263158\n",
      "This is epoch number: 6\n",
      "train accuracy on epoch 6: 1.0\n",
      "validation accuracy on epoch 6: 0.9736842105263158\n",
      "This is epoch number: 7\n",
      "train accuracy on epoch 7: 1.0\n",
      "validation accuracy on epoch 7: 0.9736842105263158\n",
      "This is epoch number: 8\n",
      "train accuracy on epoch 8: 1.0\n",
      "validation accuracy on epoch 8: 0.9736842105263158\n",
      "This is epoch number: 9\n",
      "train accuracy on epoch 9: 1.0\n",
      "validation accuracy on epoch 9: 0.9736842105263158\n",
      "This is epoch number: 10\n",
      "train accuracy on epoch 10: 1.0\n",
      "validation accuracy on epoch 10: 0.9736842105263158\n",
      "This is epoch number: 11\n",
      "train accuracy on epoch 11: 1.0\n",
      "validation accuracy on epoch 11: 0.9736842105263158\n",
      "This is epoch number: 12\n",
      "train accuracy on epoch 12: 1.0\n",
      "validation accuracy on epoch 12: 0.9736842105263158\n",
      "This is epoch number: 13\n",
      "train accuracy on epoch 13: 1.0\n",
      "validation accuracy on epoch 13: 0.9736842105263158\n",
      "This is epoch number: 14\n",
      "train accuracy on epoch 14: 1.0\n",
      "validation accuracy on epoch 14: 0.9736842105263158\n",
      "This is epoch number: 15\n",
      "train accuracy on epoch 15: 1.0\n",
      "validation accuracy on epoch 15: 0.9736842105263158\n",
      "This is epoch number: 16\n",
      "train accuracy on epoch 16: 1.0\n",
      "validation accuracy on epoch 16: 0.9736842105263158\n",
      "This is epoch number: 17\n",
      "train accuracy on epoch 17: 1.0\n",
      "validation accuracy on epoch 17: 0.9736842105263158\n",
      "This is epoch number: 18\n",
      "train accuracy on epoch 18: 1.0\n",
      "validation accuracy on epoch 18: 0.9736842105263158\n",
      "This is epoch number: 19\n",
      "train accuracy on epoch 19: 1.0\n",
      "validation accuracy on epoch 19: 0.9736842105263158\n",
      "This is epoch number: 20\n",
      "train accuracy on epoch 20: 1.0\n",
      "validation accuracy on epoch 20: 0.9736842105263158\n",
      "This is epoch number: 21\n",
      "train accuracy on epoch 21: 1.0\n",
      "validation accuracy on epoch 21: 0.9736842105263158\n",
      "This is epoch number: 22\n",
      "train accuracy on epoch 22: 1.0\n",
      "validation accuracy on epoch 22: 0.9736842105263158\n",
      "This is epoch number: 23\n",
      "train accuracy on epoch 23: 1.0\n",
      "validation accuracy on epoch 23: 0.9736842105263158\n",
      "This is epoch number: 24\n",
      "train accuracy on epoch 24: 1.0\n",
      "validation accuracy on epoch 24: 0.9736842105263158\n",
      "This is epoch number: 25\n",
      "train accuracy on epoch 25: 1.0\n",
      "validation accuracy on epoch 25: 0.9736842105263158\n",
      "This is epoch number: 26\n",
      "train accuracy on epoch 26: 1.0\n",
      "validation accuracy on epoch 26: 0.9736842105263158\n",
      "This is epoch number: 27\n",
      "train accuracy on epoch 27: 1.0\n",
      "validation accuracy on epoch 27: 0.9736842105263158\n",
      "This is epoch number: 28\n",
      "train accuracy on epoch 28: 1.0\n",
      "validation accuracy on epoch 28: 0.9736842105263158\n",
      "This is epoch number: 29\n",
      "train accuracy on epoch 29: 1.0\n",
      "validation accuracy on epoch 29: 0.9736842105263158\n",
      "This is epoch number: 30\n",
      "train accuracy on epoch 30: 1.0\n",
      "validation accuracy on epoch 30: 0.9736842105263158\n",
      "This is epoch number: 31\n",
      "train accuracy on epoch 31: 1.0\n",
      "validation accuracy on epoch 31: 0.9736842105263158\n",
      "This is epoch number: 32\n",
      "train accuracy on epoch 32: 1.0\n",
      "validation accuracy on epoch 32: 0.9736842105263158\n",
      "This is epoch number: 33\n",
      "train accuracy on epoch 33: 1.0\n",
      "validation accuracy on epoch 33: 0.9736842105263158\n",
      "This is epoch number: 34\n",
      "train accuracy on epoch 34: 1.0\n",
      "validation accuracy on epoch 34: 0.9736842105263158\n",
      "This is epoch number: 35\n",
      "train accuracy on epoch 35: 1.0\n",
      "validation accuracy on epoch 35: 0.9736842105263158\n",
      "This is epoch number: 36\n",
      "train accuracy on epoch 36: 1.0\n",
      "validation accuracy on epoch 36: 0.9736842105263158\n",
      "This is epoch number: 37\n",
      "train accuracy on epoch 37: 1.0\n",
      "validation accuracy on epoch 37: 0.9736842105263158\n",
      "This is epoch number: 38\n",
      "train accuracy on epoch 38: 1.0\n",
      "validation accuracy on epoch 38: 0.9736842105263158\n",
      "This is epoch number: 39\n",
      "train accuracy on epoch 39: 1.0\n",
      "validation accuracy on epoch 39: 0.9736842105263158\n",
      "This is epoch number: 40\n",
      "train accuracy on epoch 40: 1.0\n",
      "validation accuracy on epoch 40: 0.9736842105263158\n",
      "This is epoch number: 41\n",
      "train accuracy on epoch 41: 1.0\n",
      "validation accuracy on epoch 41: 0.9736842105263158\n",
      "This is epoch number: 42\n",
      "train accuracy on epoch 42: 1.0\n",
      "validation accuracy on epoch 42: 0.9736842105263158\n",
      "This is epoch number: 43\n",
      "train accuracy on epoch 43: 1.0\n",
      "validation accuracy on epoch 43: 0.9736842105263158\n",
      "This is epoch number: 44\n",
      "train accuracy on epoch 44: 1.0\n",
      "validation accuracy on epoch 44: 0.9736842105263158\n",
      "This is epoch number: 45\n",
      "train accuracy on epoch 45: 1.0\n",
      "validation accuracy on epoch 45: 0.9736842105263158\n",
      "This is epoch number: 46\n",
      "train accuracy on epoch 46: 1.0\n",
      "validation accuracy on epoch 46: 0.9736842105263158\n",
      "This is epoch number: 47\n",
      "train accuracy on epoch 47: 1.0\n",
      "validation accuracy on epoch 47: 0.9736842105263158\n",
      "This is epoch number: 48\n",
      "train accuracy on epoch 48: 1.0\n",
      "validation accuracy on epoch 48: 0.9736842105263158\n",
      "This is epoch number: 49\n",
      "train accuracy on epoch 49: 1.0\n",
      "validation accuracy on epoch 49: 0.9736842105263158\n",
      "This is epoch number: 50\n",
      "train accuracy on epoch 50: 1.0\n",
      "validation accuracy on epoch 50: 0.9736842105263158\n",
      "This is epoch number: 51\n",
      "train accuracy on epoch 51: 1.0\n",
      "validation accuracy on epoch 51: 0.9736842105263158\n",
      "This is epoch number: 52\n",
      "train accuracy on epoch 52: 1.0\n",
      "validation accuracy on epoch 52: 0.9736842105263158\n",
      "This is epoch number: 53\n",
      "train accuracy on epoch 53: 1.0\n",
      "validation accuracy on epoch 53: 0.9736842105263158\n",
      "This is epoch number: 54\n",
      "train accuracy on epoch 54: 1.0\n",
      "validation accuracy on epoch 54: 0.9736842105263158\n",
      "This is epoch number: 55\n",
      "train accuracy on epoch 55: 1.0\n",
      "validation accuracy on epoch 55: 0.9736842105263158\n",
      "This is epoch number: 56\n",
      "train accuracy on epoch 56: 1.0\n",
      "validation accuracy on epoch 56: 0.9736842105263158\n",
      "This is epoch number: 57\n",
      "train accuracy on epoch 57: 1.0\n",
      "validation accuracy on epoch 57: 0.9736842105263158\n",
      "This is epoch number: 58\n",
      "train accuracy on epoch 58: 1.0\n",
      "validation accuracy on epoch 58: 0.9736842105263158\n",
      "This is epoch number: 59\n",
      "train accuracy on epoch 59: 1.0\n",
      "validation accuracy on epoch 59: 0.9736842105263158\n",
      "This is epoch number: 60\n",
      "train accuracy on epoch 60: 1.0\n",
      "validation accuracy on epoch 60: 0.9736842105263158\n",
      "This is epoch number: 61\n",
      "train accuracy on epoch 61: 1.0\n",
      "validation accuracy on epoch 61: 0.9736842105263158\n",
      "This is epoch number: 62\n",
      "train accuracy on epoch 62: 1.0\n",
      "validation accuracy on epoch 62: 0.9736842105263158\n",
      "This is epoch number: 63\n",
      "train accuracy on epoch 63: 1.0\n",
      "validation accuracy on epoch 63: 0.9736842105263158\n",
      "This is epoch number: 64\n",
      "train accuracy on epoch 64: 1.0\n",
      "validation accuracy on epoch 64: 0.9736842105263158\n",
      "This is epoch number: 65\n",
      "train accuracy on epoch 65: 1.0\n",
      "validation accuracy on epoch 65: 0.9736842105263158\n",
      "This is epoch number: 66\n",
      "train accuracy on epoch 66: 1.0\n",
      "validation accuracy on epoch 66: 0.9736842105263158\n",
      "This is epoch number: 67\n",
      "train accuracy on epoch 67: 1.0\n",
      "validation accuracy on epoch 67: 0.9736842105263158\n",
      "This is epoch number: 68\n",
      "train accuracy on epoch 68: 1.0\n",
      "validation accuracy on epoch 68: 0.9736842105263158\n",
      "This is epoch number: 69\n",
      "train accuracy on epoch 69: 1.0\n",
      "validation accuracy on epoch 69: 0.9736842105263158\n",
      "This is epoch number: 70\n",
      "train accuracy on epoch 70: 1.0\n",
      "validation accuracy on epoch 70: 0.9736842105263158\n",
      "This is epoch number: 71\n",
      "train accuracy on epoch 71: 1.0\n",
      "validation accuracy on epoch 71: 0.9736842105263158\n",
      "This is epoch number: 72\n",
      "train accuracy on epoch 72: 1.0\n",
      "validation accuracy on epoch 72: 0.9736842105263158\n",
      "This is epoch number: 73\n",
      "train accuracy on epoch 73: 1.0\n",
      "validation accuracy on epoch 73: 0.9736842105263158\n",
      "This is epoch number: 74\n",
      "train accuracy on epoch 74: 1.0\n",
      "validation accuracy on epoch 74: 0.9736842105263158\n",
      "This is epoch number: 75\n",
      "train accuracy on epoch 75: 1.0\n",
      "validation accuracy on epoch 75: 0.9736842105263158\n",
      "This is epoch number: 76\n",
      "train accuracy on epoch 76: 1.0\n",
      "validation accuracy on epoch 76: 0.9736842105263158\n",
      "This is epoch number: 77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy on epoch 77: 1.0\n",
      "validation accuracy on epoch 77: 0.9736842105263158\n",
      "This is epoch number: 78\n",
      "train accuracy on epoch 78: 1.0\n",
      "validation accuracy on epoch 78: 0.9736842105263158\n",
      "This is epoch number: 79\n",
      "train accuracy on epoch 79: 1.0\n",
      "validation accuracy on epoch 79: 0.9736842105263158\n",
      "This is epoch number: 80\n",
      "train accuracy on epoch 80: 1.0\n",
      "validation accuracy on epoch 80: 0.9736842105263158\n",
      "This is epoch number: 81\n",
      "train accuracy on epoch 81: 1.0\n",
      "validation accuracy on epoch 81: 0.9736842105263158\n",
      "This is epoch number: 82\n",
      "train accuracy on epoch 82: 1.0\n",
      "validation accuracy on epoch 82: 0.9736842105263158\n",
      "This is epoch number: 83\n",
      "train accuracy on epoch 83: 1.0\n",
      "validation accuracy on epoch 83: 0.9736842105263158\n",
      "This is epoch number: 84\n",
      "train accuracy on epoch 84: 1.0\n",
      "validation accuracy on epoch 84: 0.9736842105263158\n",
      "This is epoch number: 85\n",
      "train accuracy on epoch 85: 1.0\n",
      "validation accuracy on epoch 85: 0.9736842105263158\n",
      "This is epoch number: 86\n",
      "train accuracy on epoch 86: 1.0\n",
      "validation accuracy on epoch 86: 0.9736842105263158\n",
      "This is epoch number: 87\n",
      "train accuracy on epoch 87: 1.0\n",
      "validation accuracy on epoch 87: 0.9736842105263158\n",
      "This is epoch number: 88\n",
      "train accuracy on epoch 88: 1.0\n",
      "validation accuracy on epoch 88: 0.9736842105263158\n",
      "This is epoch number: 89\n",
      "train accuracy on epoch 89: 1.0\n",
      "validation accuracy on epoch 89: 0.9736842105263158\n",
      "This is epoch number: 90\n",
      "train accuracy on epoch 90: 1.0\n",
      "validation accuracy on epoch 90: 0.9736842105263158\n",
      "This is epoch number: 91\n",
      "train accuracy on epoch 91: 1.0\n",
      "validation accuracy on epoch 91: 0.9736842105263158\n",
      "This is epoch number: 92\n",
      "train accuracy on epoch 92: 1.0\n",
      "validation accuracy on epoch 92: 0.9736842105263158\n",
      "This is epoch number: 93\n",
      "train accuracy on epoch 93: 1.0\n",
      "validation accuracy on epoch 93: 0.9736842105263158\n",
      "This is epoch number: 94\n",
      "train accuracy on epoch 94: 1.0\n",
      "validation accuracy on epoch 94: 0.9736842105263158\n",
      "This is epoch number: 95\n",
      "train accuracy on epoch 95: 1.0\n",
      "validation accuracy on epoch 95: 0.9736842105263158\n",
      "This is epoch number: 96\n",
      "train accuracy on epoch 96: 1.0\n",
      "validation accuracy on epoch 96: 0.9736842105263158\n",
      "This is epoch number: 97\n",
      "train accuracy on epoch 97: 1.0\n",
      "validation accuracy on epoch 97: 0.9736842105263158\n",
      "This is epoch number: 98\n",
      "train accuracy on epoch 98: 1.0\n",
      "validation accuracy on epoch 98: 0.9736842105263158\n",
      "This is epoch number: 99\n",
      "train accuracy on epoch 99: 1.0\n",
      "validation accuracy on epoch 99: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_train, Y_train = helpers.load_data(os.path.join(\"..\", \"data\"), \"dtrain123.dat\")\n",
    "X_val, Y_val = helpers.load_data(os.path.join(\"..\", \"data\"), \"dtest123.dat\")\n",
    "\n",
    "Y_train = Y_train - 1\n",
    "Y_val = Y_val - 1\n",
    "\n",
    "epochs=100\n",
    "n_classes=3\n",
    "kernel_type = 'polynomial'\n",
    "d=3\n",
    "\n",
    "history = train_kernel_perceptron(X_train, Y_train, \n",
    "                                  X_val, Y_val, epochs,\n",
    "                                  kernel_type, d, n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold_cross_val(epochs, data_path = os.path.join('..', 'data'), \n",
    "                         name = 'zipcombo.dat', kernel_type = 'polynomial', \n",
    "                         d = 5, n_classes=10, k = 5):\n",
    "    '''\n",
    "    Execute the training steps above and generate\n",
    "    the results that have been specified in the report.\n",
    "    '''\n",
    "    # Prepare data for the perceptron\n",
    "    X, Y = helpers.load_data(data_path, name)\n",
    "    \n",
    "    # Shuffle the dataset before splitting it\n",
    "    X, Y = helpers.shuffle_data(X, Y)\n",
    "    \n",
    "    # Split the data into training and validation set \n",
    "    X_folds, Y_folds = helpers.get_k_folds(X, Y, k)\n",
    "    \n",
    "    # Initiate histories object\n",
    "    histories = []\n",
    "    \n",
    "    # Now go through each fold : every fold becomes the hold-out set at least once\n",
    "    for fold_no in range(k):\n",
    "        \n",
    "        # Put in the x-values\n",
    "        X_train = np.concatenate(X_folds[:fold_no] + X_folds[fold_no+1:])\n",
    "        X_val = X_folds[fold_no]\n",
    "        \n",
    "        # Put in the Y values\n",
    "        Y_train = np.concatenate(Y_folds[:fold_no] + Y_folds[fold_no+1:])\n",
    "        Y_val =  Y_folds[fold_no]\n",
    "        \n",
    "        # Call the perceptron training with the given epochs\n",
    "        history = train_kernel_perceptron(X_train, Y_train, \n",
    "                                          X_val, Y_val, epochs,\n",
    "                                          kernel_type, d, n_classes)\n",
    "        \n",
    "        # Append to the histories file the epoch by epoch record of each fold\n",
    "        histories.append(history)\n",
    "    \n",
    "    # Get avg. accuracies by epoch across folds\n",
    "    avg_history = helpers.get_avg_results(histories)\n",
    "    \n",
    "    # Return best epoch according to dev. accuracy and the associated accuracies on both datasets\n",
    "    best_epoch, best_training_accuracy, best_dev_accuracy = helpers.get_best_results(avg_history)\n",
    "        \n",
    "    # Return statement\n",
    "    return(avg_history, best_epoch, best_training_accuracy, best_dev_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple(params, kwargs):\n",
    "    \n",
    "    histories = {\n",
    "        \n",
    "        'params': params, \n",
    "        'history': [],\n",
    "        'best_epoch': [],\n",
    "        'best_training_accuracy': [],\n",
    "        'best_dev_accuracy': [],\n",
    "    }\n",
    "    \n",
    "    for param in params:\n",
    "        history, best_epoch, best_training_accuracy, best_dev_accuracy = run_perceptron_training(**kwargs, d=param)\n",
    "        histories['history'].append(history)\n",
    "        histories['best_epoch'].append(best_epoch)\n",
    "        histories['best_training_accuracy'].append(best_training_accuracy)\n",
    "        histories['best_dev_accuracy'].append(best_dev_accuracy)\n",
    "    \n",
    "    return(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(params, kwargs):\n",
    "    \n",
    "    \n",
    "    histories = {\n",
    "        \n",
    "            'params': params, \n",
    "            'best_epoch': [],\n",
    "            'best_training_accuracy': [],\n",
    "            'best_dev_accuracy': [],\n",
    "    }\n",
    "    \n",
    "    for param in params: \n",
    "        _, best_epoch, best_training_accuracy, best_dev_accuracy = run_k_fold_cross_val(d=param, **kwargs)\n",
    "        histories['best_epoch'].append(best_epoch)\n",
    "        histories['best_training_accuracy'].append(best_training_accuracy)\n",
    "        histories['best_dev_accuracy'].append(best_dev_accuracy)\n",
    "    \n",
    "    \n",
    "    return(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(13290138)\n",
    "\n",
    "# Store parameter list\n",
    "params = [1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store arguments for this\n",
    "multiple_run_args = {\n",
    "    \n",
    "    'epochs': 100, \n",
    "    'data_path': os.path.join('..', 'data'), \n",
    "    'name': 'zipcombo.dat', \n",
    "    'kernel_type': 'polynomial', \n",
    "    'n_classes': 10,\n",
    "    'train_percent': 0.8   \n",
    "}\n",
    "\n",
    "# Call training function multiple runs\n",
    "multiple_histories = run_multiple(params, multiple_run_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the best parameters with the polynomial kernel\n",
    "grid_search_args = {\n",
    "    \n",
    "    'epochs': 100, \n",
    "    'data_path': os.path.join('..', 'data'), \n",
    "    'name': 'zipcombo.dat', \n",
    "    'kernel_type': 'polynomial', \n",
    "    'n_classes': 10,\n",
    "    'k': 5\n",
    "    \n",
    "}\n",
    "\n",
    "# Call training function with k-fold cross validation\n",
    "cross_val_histories = run_grid_search(params, grid_search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do for this script:\n",
    "# Make plots of losses to see whether it is converging\n",
    "# Check shapes of all matrices\n",
    "# Take a look at the actual data in each matrix\n",
    "# Take a look at each weight\n",
    "# Take a look at whether kernel arguments are being sent in correctly\n",
    "# Test Gaussian kernel\n",
    "\n",
    "# Potential report content\n",
    "# Talk about effect of dimensionality on overfitting\n",
    "# Expand the Gaussian kernel into its feature map and speak about the role of c as a regularizer\n",
    "# Try to answer the question: for what values of C does Gaussian kernel mimic a polynomial kernel? \n",
    "# Potentially make a plot for the above\n",
    "\n",
    "# Questions: \n",
    "# Do we shuffle the data at each epoch?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
