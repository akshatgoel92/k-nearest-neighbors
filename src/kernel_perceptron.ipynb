{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do for this script:\n",
    "# Make plots of losses to see whether it is converging\n",
    "# Check shapes of all matrices\n",
    "# Take a look at the actual data in each matrix\n",
    "# Take a look at each weight\n",
    "# Take a look at whether kernel arguments are being sent in correctly\n",
    "\n",
    "# Test Gaussian kernel\n",
    "# Implement 'many runs' mode to do 20 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions: \n",
    "# Do we shuffle the data at each epoch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential report content\n",
    "# Talk about effect of dimensionality on overfitting\n",
    "# Expand the Gaussian kernel into its feature map and speak about the role of c as a regularizer\n",
    "# Try to answer the question: for what values of C does Gaussian kernel mimic a polynomial kernel? \n",
    "# Potentially make a plot for the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(alpha, K_examples):\n",
    "    '''\n",
    "    Returns raw predictions and class predictions\n",
    "    given alpha weights and Gram matrix K_examples.\n",
    "    '''\n",
    "    # Take the maximum argument in each column\n",
    "    Y_hat = alpha @ K_examples\n",
    "    preds = np.argmax(Y_hat, axis = 0)\n",
    "    \n",
    "    # Return statement\n",
    "    return(Y_hat, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kernel_perceptron(X_train, Y_train, X_val, Y_val, epochs, lr, kernel_type, kernel_args, n_classes):\n",
    "    '''\n",
    "    This is the main training loop for\n",
    "    the kernel perceptron algorithm.\n",
    "    '''\n",
    "    # Store a record of training and validation accuracies and other data from each epoch\n",
    "    history = {\n",
    "        \"train_accuracies\": [],\n",
    "        \"val_accuracies\": [],\n",
    "        \"train_cf\": [],\n",
    "        \"val_cf\": []\n",
    "    }\n",
    "    \n",
    "    # Transform X according to the user specified kernel\n",
    "    # Can be either polynomial kernel or Gaussian kernel\n",
    "    # Do this for both training and validation set\n",
    "    if kernel_type == 'polynomial':\n",
    "        K_train = helpers.get_polynomial_kernel(X_train, X_train, **kernel_args)\n",
    "        K_val = helpers.get_polynomial_kernel(X_train, X_val, **kernel_args)\n",
    "    \n",
    "    elif kernel_type == 'gaussian':\n",
    "        K_train = helpers.get_gaussian_kernel(X_train, X_train, **kernel_args)\n",
    "        K_val = helpers.get_gaussian_kernel(X_train, X_val, **kernel_args)\n",
    "    \n",
    "    # Initialize alpha weights and store \n",
    "    # the number of samples\n",
    "    alpha = np.zeros((n_classes, K_train.shape[0]))\n",
    "    n_samples = max(Y_train.shape)\n",
    "    \n",
    "    # Run for a fixed user-specified number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Print the epoch number to track progress\n",
    "        print('This is epoch number: {}'.format(epoch))\n",
    "\n",
    "        # Do this for each example in the dataset\n",
    "        for i in range(n_samples):\n",
    "\n",
    "            # Compute the prediction with the current weights:\n",
    "            # dim(A) --> (10, 6199), dim(X_train[i, :]) ---> (6199, 1) ====> dim(y_hat) --> 10 X 1\n",
    "            Y_hat, _ = get_predictions(alpha, K_train[i, :])\n",
    "            \n",
    "            # Now first make a matrix Y with dim(Y) ---> (n_classes,) which is only filled with -1\n",
    "            # Then get the label from the Y_train matrix\n",
    "            # If this label is 6 then we want to change the 6th index to 1\n",
    "            Y = np.full(n_classes, -1)\n",
    "            Y[int(Y_train[i])] = 1\n",
    "            \n",
    "            # Compute sign of predictions\n",
    "            # This is used in the update\n",
    "            signs = np.ones(Y_hat.shape)\n",
    "            signs[Y_hat <= 0] = -1\n",
    "            \n",
    "            # Check if the prediction is correct against the labels\n",
    "            # If it is correct we don't need to make any updates: we just move to the next iteration\n",
    "            # If it is not correct then we update the weights and biases in the direction of the label\n",
    "            alpha[Y*Y_hat <= 0, i] -= (signs[Y*Y_hat <= 0]) \n",
    "            \n",
    "        # We finally compute predictions and accuracy at the end of each epoch\n",
    "        # It is a mistake if the class with the highest predicted value does not equal the true label\n",
    "        # mistakes += int((np.argmax(Y_hat) + 1) != int(Y_train[i]))\n",
    "        Y_hat_train, preds_train = get_predictions(alpha, K_train)\n",
    "        train_accuracy = helpers.get_accuracy(Y_train, preds_train)\n",
    "            \n",
    "        # Now we compute validation predictions\n",
    "        Y_hat_val, preds_val = get_predictions(alpha, K_val)\n",
    "        val_accuracy = helpers.get_accuracy(Y_val, preds_val)\n",
    "        \n",
    "        # At the end of each epoch we get confusion matrices\n",
    "        train_cf = helpers.get_confusion_matrix(Y_train, preds_train)\n",
    "        val_cf = helpers.get_confusion_matrix(Y_val, preds_val)\n",
    "        \n",
    "        # We append to the history dictionary as a record\n",
    "        history['train_accuracies'].append(train_accuracy)\n",
    "        history['val_accuracies'].append(val_accuracy)\n",
    "        history['train_cf'].append(train_cf)\n",
    "        history['val_cf'].append(val_cf)\n",
    "        \n",
    "        # We print the accuracies at the end of each epoch\n",
    "        msg = 'The number of {} accuracy on epoch {} is {}...'\n",
    "        print(msg.format('train', epoch, train_accuracy))\n",
    "        print(msg.format('validation', epoch, val_accuracy))\n",
    "    \n",
    "    # Return statement\n",
    "    return(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_perceptron_training(epochs, lr, data_path = os.path.join('..', 'data'), name = 'zipcombo.dat', \n",
    "                            kernel_type = 'polynomial', d = 5, n_classes=10, train_percent=0.8):\n",
    "    '''\n",
    "    Execute the training steps above and generate\n",
    "    the results that have been specified in the report.\n",
    "    '''\n",
    "    # Prepare data for the perceptron\n",
    "    X, Y = helpers.load_data(data_path, name)\n",
    "    \n",
    "    # Shuffle the dataset before splitting it\n",
    "    X, Y = helpers.shuffle_data(X, Y)\n",
    "    \n",
    "    # Split the data into training and validation set \n",
    "    X_train, X_val, Y_train, Y_val = helpers.split_data(X, Y, train_percent)\n",
    "    \n",
    "    # Construct kernel arguments dictionary\n",
    "    if kernel_type == 'polynomial': kernel_args = {'d': d}\n",
    "\n",
    "    # Call the perceptron training with the given epochs\n",
    "    history = train_kernel_perceptron(X_train, Y_train, \n",
    "                                      X_val, Y_val, epochs, lr, \n",
    "                                      kernel_type, kernel_args, n_classes)\n",
    "    \n",
    "    # Return statement\n",
    "    return(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold_cross_val(epochs, lr, data_path = os.path.join('..', 'data'), \n",
    "                         name = 'zipcombo.dat', kernel_type = 'polynomial', \n",
    "                         d = 5, n_classes=10, k = 5):\n",
    "    '''\n",
    "    Execute the training steps above and generate\n",
    "    the results that have been specified in the report.\n",
    "    '''\n",
    "    # Prepare data for the perceptron\n",
    "    X, Y = helpers.load_data(data_path, name)\n",
    "    \n",
    "    # Shuffle the dataset before splitting it\n",
    "    X, Y = helpers.shuffle_data(X, Y)\n",
    "    \n",
    "    # Construct kernel arguments dictionary\n",
    "    if kernel_type == 'polynomial': kernel_args = {'d': d}\n",
    "    \n",
    "    # Split the data into training and validation set \n",
    "    X_folds, Y_folds = helpers.get_k_folds(X, Y, k)\n",
    "    \n",
    "    # Initiate histories object\n",
    "    histories = []\n",
    "    \n",
    "    # Now go through each fold : every fold becomes the hold-out set at least once\n",
    "    for fold_no in range(k):\n",
    "        \n",
    "        # Put in the x-values\n",
    "        X_train = np.concatenate(X_folds[:fold_no] + X_folds[fold_no+1:])\n",
    "        X_val = X_folds[fold_no]\n",
    "        \n",
    "        # Put in the Y values\n",
    "        Y_train = np.concatenate(Y_folds[:fold_no] + Y_folds[fold_no+1:])\n",
    "        Y_val =  Y_folds[fold_no]\n",
    "        \n",
    "        # Call the perceptron training with the given epochs\n",
    "        history = train_kernel_perceptron(X_train, Y_train, \n",
    "                                          X_val, Y_val, epochs, lr, \n",
    "                                          kernel_type, kernel_args, n_classes)\n",
    "        \n",
    "        # Append to the histories file\n",
    "        histories.append(history)\n",
    "\n",
    "        \n",
    "    # Return statement\n",
    "    return(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is epoch number: 0\n",
      "The number of train accuracy on epoch 0 is 0.9892444205431568...\n",
      "The number of validation accuracy on epoch 0 is 0.9661290322580646...\n",
      "This is epoch number: 1\n",
      "The number of train accuracy on epoch 1 is 0.996504436676526...\n",
      "The number of validation accuracy on epoch 1 is 0.9715053763440861...\n",
      "This is epoch number: 2\n",
      "The number of train accuracy on epoch 2 is 0.9994622210271579...\n",
      "The number of validation accuracy on epoch 2 is 0.9709677419354839...\n",
      "This is epoch number: 3\n",
      "The number of train accuracy on epoch 3 is 0.9987899973111052...\n",
      "The number of validation accuracy on epoch 3 is 0.9688172043010753...\n",
      "This is epoch number: 4\n",
      "The number of train accuracy on epoch 4 is 0.9997311105135789...\n",
      "The number of validation accuracy on epoch 4 is 0.9747311827956989...\n",
      "This is epoch number: 5\n",
      "The number of train accuracy on epoch 5 is 0.9997311105135789...\n",
      "The number of validation accuracy on epoch 5 is 0.9736559139784946...\n",
      "This is epoch number: 6\n",
      "The number of train accuracy on epoch 6 is 0.9997311105135789...\n",
      "The number of validation accuracy on epoch 6 is 0.9747311827956989...\n",
      "This is epoch number: 7\n",
      "The number of train accuracy on epoch 7 is 0.9997311105135789...\n",
      "The number of validation accuracy on epoch 7 is 0.9741935483870968...\n",
      "This is epoch number: 8\n",
      "The number of train accuracy on epoch 8 is 0.9997311105135789...\n",
      "The number of validation accuracy on epoch 8 is 0.9741935483870968...\n",
      "This is epoch number: 9\n",
      "The number of train accuracy on epoch 9 is 0.9997311105135789...\n",
      "The number of validation accuracy on epoch 9 is 0.9741935483870968...\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(13290138)\n",
    "\n",
    "# Call training function once\n",
    "history = run_perceptron_training(epochs=10, lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is epoch number: 0\n",
      "The number of train accuracy on epoch 0 is 0.9899166442592094...\n",
      "The number of validation accuracy on epoch 0 is 0.9682795698924731...\n",
      "This is epoch number: 1\n",
      "The number of train accuracy on epoch 1 is 0.9971766603925787...\n",
      "The number of validation accuracy on epoch 1 is 0.9666666666666667...\n",
      "This is epoch number: 0\n",
      "The number of train accuracy on epoch 0 is 0.9892444205431568...\n",
      "The number of validation accuracy on epoch 0 is 0.9548387096774194...\n",
      "This is epoch number: 1\n",
      "The number of train accuracy on epoch 1 is 0.9962355471901049...\n",
      "The number of validation accuracy on epoch 1 is 0.9655913978494624...\n",
      "This is epoch number: 0\n",
      "The number of train accuracy on epoch 0 is 0.9858833019628932...\n",
      "The number of validation accuracy on epoch 0 is 0.9596774193548387...\n",
      "This is epoch number: 1\n",
      "The number of train accuracy on epoch 1 is 0.9966388814197364...\n",
      "The number of validation accuracy on epoch 1 is 0.9634408602150538...\n",
      "This is epoch number: 0\n",
      "The number of train accuracy on epoch 0 is 0.9802392794730475...\n",
      "The number of validation accuracy on epoch 0 is 0.949435180204411...\n",
      "This is epoch number: 1\n",
      "The number of train accuracy on epoch 1 is 0.9974458932652238...\n",
      "The number of validation accuracy on epoch 1 is 0.9682625067240452...\n",
      "This is epoch number: 0\n",
      "The number of train accuracy on epoch 0 is 0.982927812878075...\n",
      "The number of validation accuracy on epoch 0 is 0.9499731038192577...\n",
      "This is epoch number: 1\n",
      "The number of train accuracy on epoch 1 is 0.9951606398709504...\n",
      "The number of validation accuracy on epoch 1 is 0.972027972027972...\n"
     ]
    }
   ],
   "source": [
    "# Call training function once\n",
    "history = run_k_fold_cross_val(epochs=2, lr=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
